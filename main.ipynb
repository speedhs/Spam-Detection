{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import nltk\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelBinarizer\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from wordcloud import WordCloud,STOPWORDS\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize,sent_tokenize\n","from bs4 import BeautifulSoup\n","import re,string,unicodedata\n","from nltk.tokenize.toktok import ToktokTokenizer\n","from nltk.stem import LancasterStemmer,WordNetLemmatizer\n","from sklearn.linear_model import LogisticRegression,SGDClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n","from sklearn.model_selection import train_test_split\n","from string import punctuation\n","from nltk import pos_tag\n","from nltk.corpus import wordnet"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.isna().sum() #Checking if there are any Nan values "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.Category.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.Category.replace('ham' , 1 ,inplace = True)\n","df.Category.replace('spam' , 0 ,inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stop = set(stopwords.words('english'))\n","punctuation = list(string.punctuation)\n","stop.update(punctuation)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_simple_pos(tag):\n","    if tag.startswith('J'):\n","        return wordnet.ADJ\n","    elif tag.startswith('V'):\n","        return wordnet.VERB\n","    elif tag.startswith('N'):\n","        return wordnet.NOUN\n","    elif tag.startswith('R'):\n","        return wordnet.ADV\n","    else:\n","        return wordnet.NOUN"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["lemmatizer = WordNetLemmatizer()\n","def lemmatize_words(text):\n","    final_text = []\n","    for i in text.split():\n","        if i.strip().lower() not in stop:\n","            pos = pos_tag([i.strip()])\n","            word = lemmatizer.lemmatize(i.strip(),get_simple_pos(pos[0][1]))\n","            final_text.append(word.lower())\n","    return final_text        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.Message = df.Message.apply(lemmatize_words)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def join_text(text):\n","    string = ''\n","    for i in text:\n","        string += i.strip() +' '\n","    return string    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.Message = df.Message.apply(join_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_message = df.Message[:5000]\n","test_message = df.Message[5000:]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n","#transformed train reviews\n","cv_train_reviews=cv.fit_transform(train_message)\n","#transformed test reviews\n","cv_test_reviews=cv.transform(test_message)\n","\n","print('BOW_cv_train:',cv_train_reviews.shape)\n","print('BOW_cv_test:',cv_test_reviews.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n","#transformed train reviews\n","tv_train_reviews=tv.fit_transform(train_message)\n","#transformed test reviews\n","tv_test_reviews=tv.transform(test_message)\n","print('Tfidf_train:',tv_train_reviews.shape)\n","print('Tfidf_test:',tv_test_reviews.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_category = df.Category[:5000]\n","test_category = df.Category[5000:]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n","#Fitting the model for Bag of words\n","lr_bow=lr.fit(cv_train_reviews,train_category)\n","print(lr_bow)\n","#Fitting the model for tfidf features\n","lr_tfidf=lr.fit(tv_train_reviews,train_category)\n","print(lr_tfidf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Predicting the model for bag of words\n","lr_bow_predict=lr.predict(cv_test_reviews)\n","##Predicting the model for tfidf features\n","lr_tfidf_predict=lr.predict(tv_test_reviews)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Accuracy score for bag of words\n","lr_bow_score=accuracy_score(test_category,lr_bow_predict)\n","print(\"lr_bow_score :\",lr_bow_score)\n","#Accuracy score for tfidf features\n","lr_tfidf_score=accuracy_score(test_category,lr_tfidf_predict)\n","print(\"lr_tfidf_score :\",lr_tfidf_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Classification report for bag of words\n","lr_bow_report=classification_report(test_category,lr_bow_predict,target_names=['spam','ham'])\n","print(lr_bow_report)\n","\n","#Classification report for tfidf features\n","lr_tfidf_report=classification_report(test_category,lr_tfidf_predict,target_names=['spam','ham'])\n","print(lr_tfidf_report)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#training the model\n","mnb=MultinomialNB()\n","#fitting the nb for bag of words\n","mnb_bow=mnb.fit(cv_train_reviews,train_category)\n","print(mnb_bow)\n","#fitting the nb for tfidf features\n","mnb_tfidf=mnb.fit(tv_train_reviews,train_category)\n","print(mnb_tfidf)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Predicting the model for bag of words\n","mnb_bow_predict=mnb.predict(cv_test_reviews)\n","#Predicting the model for tfidf features\n","mnb_tfidf_predict=mnb.predict(tv_test_reviews)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Accuracy score for bag of words\n","mnb_bow_score=accuracy_score(test_category,mnb_bow_predict)\n","print(\"mnb_bow_score :\",mnb_bow_score)\n","#Accuracy score for tfidf features\n","mnb_tfidf_score=accuracy_score(test_category,mnb_tfidf_predict)\n","print(\"mnb_tfidf_score :\",mnb_tfidf_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mnb_bow_report = classification_report(test_category,mnb_bow_predict,target_names = ['spam','ham'])\n","print(mnb_bow_report)\n","mnb_tfidf_report = classification_report(test_category,mnb_tfidf_predict,target_names = ['spam','ham'])\n","print(mnb_tfidf_report)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ham_words = df[df.Category == 1].Message\n","spam_words = df[df.Category == 0].Message"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize = (10,10))\n","ham_text = ham_words[0]\n","wc = WordCloud(height = 500 , width = 1000 , max_words = 100).generate(ham_text)\n","plt.imshow(wc,interpolation='bilinear')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize = (10,10))\n","spam_text = spam_words[56]\n","wc = WordCloud(height = 500 , width = 1000 , max_words = 100).generate(spam_text)\n","plt.imshow(wc,interpolation='bilinear')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
